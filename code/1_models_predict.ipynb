{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Administrator.SKY-20170617YWV\\Anaconda2\\lib\\site-packages\\gensim\\utils.py:1197: UserWarning: detected Windows; aliasing chunkize to chunkize_serial\n",
      "  warnings.warn(\"detected Windows; aliasing chunkize to chunkize_serial\")\n",
      "C:\\Users\\Administrator.SKY-20170617YWV\\Anaconda2\\lib\\site-packages\\sklearn\\cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import sys\n",
    "import string\n",
    "import numpy as np\n",
    "import lda\n",
    "import gensim\n",
    "\n",
    "from sklearn import feature_extraction\n",
    "from sklearn.cross_validation import train_test_split \n",
    "from sklearn.metrics import precision_recall_curve\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import  CountVectorizer\n",
    "from sklearn.feature_extraction.text import HashingVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.feature_selection import SelectKBest, chi2\n",
    "from sklearn.naive_bayes import MultinomialNB  \n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC \n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn import metrics  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def loadClassData(filename):\n",
    "    dataList  = []\n",
    "    for line in open('../input/'+filename,'r').readlines():#读取分类序列\n",
    "        dataList.append(int(line.strip()))\n",
    "    return dataList\n",
    "\n",
    "def loadTrainData(filename):\n",
    "    dataList  = []\n",
    "    for line in open('../input/'+filename,'r').readlines():#读取分类序列\n",
    "        dataList.append(line.strip())\n",
    "    return dataList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "trainCorpus = []\n",
    "classLabel = []\n",
    "\n",
    "classLabel = loadClassData('classLabel.txt')\n",
    "trainCorpus = loadTrainData('trainLeft.txt')  \n",
    "trainData, testData, trainLabel, testLabel = train_test_split(trainCorpus, classLabel, test_size = 0.2,random_state=0) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#计算F值分数  \n",
    "def totalScore(pred,y_test):\n",
    "    A = 0\n",
    "    C = 0\n",
    "    B = 0\n",
    "    D = 0\n",
    "    for i in range(len(pred)):\n",
    "        if y_test[i] == 0:\n",
    "            if pred[i] == 0:\n",
    "                A += 1\n",
    "            elif pred[i] == 1:\n",
    "                B += 1\n",
    "        elif y_test[i] == 1:\n",
    "            if pred[i] == 0:\n",
    "                C += 1\n",
    "            elif pred[i] == 1:\n",
    "                D +=1\n",
    "    rb_pr = 1.0*D/(B+D)\n",
    "    rb_re = 1.0*D/(C+D)\n",
    "    rt_pr = 1.0*A/(A+C)\n",
    "    rt_re = 1.0*A/(A+B)\n",
    "    \n",
    "    Frb = 0.65*rb_pr + 0.35*rb_re\n",
    "    Frt = 0.65*rt_pr + 0.35*rt_re\n",
    "    Ftotal = 0.7*Frb + 0.3*Frt\n",
    "    print Ftotal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def logisticReg(trainData,testData,trainLabel,testLabel):\n",
    "\n",
    "    vectorizer = CountVectorizer(binary=True)#0.971387536109\n",
    "#     vectorizer =TfidfVectorizer(binary=True) #0.931660369875\n",
    "    fea_train = vectorizer.fit_transform(trainData)\n",
    "    fea_test = vectorizer.transform(testData);  \n",
    "    clf =  LogisticRegression()\n",
    "    clf.fit(fea_train,np.array(trainLabel)) \n",
    "    pred= clf.predict(fea_test)\n",
    "    totalScore(pred,testLabel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def withoutFeature(trainData,testData,trainLabel,testLabel):\n",
    "    vectorizer = CountVectorizer(binary=True) #0.974682247615\n",
    "#     vectorizer =TfidfVectorizer(binary=True) #0.963440017657\n",
    "    fea_train = vectorizer.fit_transform(trainData)\n",
    "    fea_test = vectorizer.transform(testData)\n",
    "    print type(fea_test)\n",
    "    print 'Size of fea_train:' + repr(fea_train.shape) \n",
    "    print 'Size of fea_test:' + repr(fea_test.shape) \n",
    "    print fea_train.nnz\n",
    "    print fea_test.nnz\n",
    "    clf = LinearSVC( C= 0.8)\n",
    "    clf.fit(fea_train,np.array(trainLabel))  \n",
    "    pred = clf.predict(fea_test) \n",
    "    totalScore(pred,testLabel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#navie bayes classifier\n",
    "def nbClassifier(trainData,testData,trainLabel,testLabel):\n",
    "#     vectorizer = CountVectorizer(binary=True) #0.906835307297\n",
    "    vectorizer =TfidfVectorizer(binary=True) #0.921827974983\n",
    "    fea_train = vectorizer.fit_transform(trainData)\n",
    "    fea_test = vectorizer.transform(testData);  \n",
    "    print 'Size of fea_train:' + repr(fea_train.shape) \n",
    "    print 'Size of fea_test:' + repr(fea_test.shape) \n",
    "    print fea_train.nnz\n",
    "    print fea_test.nnz\n",
    "\n",
    "    clf = MultinomialNB(alpha = 0.01)   \n",
    "    clf.fit(fea_train,np.array(trainLabel))\n",
    "    pred = clf.predict(fea_test)\n",
    "    totalScore(pred,testLabel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def linearSVCClassifier(trainData,testData,trainLabel,testLabel):\n",
    "    hv = HashingVectorizer(n_features =80000)\n",
    "#     vectorizer = make_pipeline(hv,TfidfTransformer()) #0.958681502859\n",
    "    vectorizer=hv #0.963931013641\n",
    "    fea_train = vectorizer.fit_transform(trainData)    #return feature vector 'fea_train' [n_samples,n_features]  \n",
    "    fea_test = vectorizer.transform(testData);  \n",
    "    print 'Size of fea_train:' + repr(fea_train.shape) \n",
    "    print 'Size of fea_train:' + repr(fea_test.shape) \n",
    "    print fea_train.nnz\n",
    "    print fea_test.nnz\n",
    "    \n",
    "    clf = LinearSVC( C= 0.8)\n",
    "    clf.fit(fea_train,np.array(trainLabel))  \n",
    "    pred = clf.predict(fea_test);  \n",
    "    totalScore(pred,testLabel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def ldaClassifier(trainData,testData,trainLabel,testLabel):\n",
    "    \n",
    "#     文档-词频矩阵\n",
    "    vectorizer = CountVectorizer(binary=True)\n",
    "    fea_train = vectorizer.fit_transform(trainData)\n",
    "    fea_test = vectorizer.transform(testData);  \n",
    "    \n",
    "#     model.topic_word_ 输出主题-词语矩阵\n",
    "#     model.doc_topic_ 输出文档主题矩阵\n",
    "    model = lda.LDA(n_topics=20,n_iter= 500,random_state=1)\n",
    "    doc_topic_train=model.fit_transform(fea_train)  \n",
    "#     doc_topic_train1=model.doc_topic_\n",
    "    doc_topic_test = model.transform(fea_test)\n",
    "    \n",
    "#     print doc_topic_train.shape\n",
    "#     print doc_topic_train1.shape\n",
    "#     print doc_topic_test.shape\n",
    "    clf = LinearSVC( C= 0.8)\n",
    "    clf.fit(doc_topic_train,np.array(trainLabel)) \n",
    "    pred = clf.predict(doc_topic_test);  \n",
    "    totalScore(pred,testLabel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def rfClassifier(trainData,testData,trainLabel,testLabel):\n",
    "    hv = HashingVectorizer(n_features = 10000,non_negative=True)\n",
    "    voctorizer = make_pipeline(hv,TfidfTransformer())  \n",
    "    fea_train = voctorizer.fit_transform(trainData)    #return feature vector 'fea_train' [n_samples,n_features]  \n",
    "    fea_test = voctorizer.transform(testData);  \n",
    "    print 'Size of fea_train:' + repr(fea_train.shape) \n",
    "    print 'Size of fea_train:' + repr(fea_test.shape) \n",
    "    print fea_train.nnz\n",
    "    print fea_test.nnz\n",
    "    \n",
    "    clf = RandomForestClassifier()\n",
    "    clf.fit(fea_train,np.array(trainLabel))  \n",
    "    pred = clf.predict(fea_test);  \n",
    "    totalScore(pred,testLabel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.971387536109\n"
     ]
    }
   ],
   "source": [
    "# CountVectorizer + LogisticRegression\n",
    "logisticReg(trainData,testData,trainLabel,testLabel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'scipy.sparse.csr.csr_matrix'>\n",
      "Size of fea_train:(40000, 62438)\n",
      "Size of fea_test:(10000, 62438)\n",
      "278526\n",
      "59942\n",
      "0.963440017657\n"
     ]
    }
   ],
   "source": [
    "# CountVectorizer + LinearSVC\n",
    "withoutFeature(trainData,testData,trainLabel,testLabel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of fea_train:(40000, 62438)\n",
      "Size of fea_test:(10000, 62438)\n",
      "278526\n",
      "59942\n",
      "0.921827974983\n"
     ]
    }
   ],
   "source": [
    "# TfidfVectorizer + MultinomialNB\n",
    "nbClassifier(trainData,testData,trainLabel,testLabel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of fea_train:(40000, 80000)\n",
      "Size of fea_train:(10000, 80000)\n",
      "278514\n",
      "69587\n",
      "0.963931013641\n"
     ]
    }
   ],
   "source": [
    "# HashingVectorizer + (TfidfTransformer)+ LinearSVC\n",
    "linearSVCClassifier(trainData,testData,trainLabel,testLabel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:lda:n_documents: 40000\n",
      "INFO:lda:vocab_size: 62438\n",
      "INFO:lda:n_words: 278526\n",
      "INFO:lda:n_topics: 20\n",
      "INFO:lda:n_iter: 500\n",
      "WARNING:lda:all zero row in document-term matrix found\n",
      "INFO:lda:<0> log likelihood: -4117538\n",
      "INFO:lda:<10> log likelihood: -3116324\n",
      "INFO:lda:<20> log likelihood: -3019215\n",
      "INFO:lda:<30> log likelihood: -2974552\n",
      "INFO:lda:<40> log likelihood: -2949624\n",
      "INFO:lda:<50> log likelihood: -2930408\n",
      "INFO:lda:<60> log likelihood: -2917653\n",
      "INFO:lda:<70> log likelihood: -2906090\n",
      "INFO:lda:<80> log likelihood: -2898187\n",
      "INFO:lda:<90> log likelihood: -2891838\n",
      "INFO:lda:<100> log likelihood: -2885895\n",
      "INFO:lda:<110> log likelihood: -2880935\n",
      "INFO:lda:<120> log likelihood: -2876240\n",
      "INFO:lda:<130> log likelihood: -2872751\n",
      "INFO:lda:<140> log likelihood: -2871348\n",
      "INFO:lda:<150> log likelihood: -2869570\n",
      "INFO:lda:<160> log likelihood: -2868331\n",
      "INFO:lda:<170> log likelihood: -2865161\n",
      "INFO:lda:<180> log likelihood: -2864482\n",
      "INFO:lda:<190> log likelihood: -2861651\n",
      "INFO:lda:<200> log likelihood: -2860433\n",
      "INFO:lda:<210> log likelihood: -2860043\n",
      "INFO:lda:<220> log likelihood: -2858781\n",
      "INFO:lda:<230> log likelihood: -2858162\n",
      "INFO:lda:<240> log likelihood: -2857811\n",
      "INFO:lda:<250> log likelihood: -2856644\n",
      "INFO:lda:<260> log likelihood: -2855060\n",
      "INFO:lda:<270> log likelihood: -2856646\n",
      "INFO:lda:<280> log likelihood: -2854417\n",
      "INFO:lda:<290> log likelihood: -2855080\n",
      "INFO:lda:<300> log likelihood: -2853675\n",
      "INFO:lda:<310> log likelihood: -2852532\n",
      "INFO:lda:<320> log likelihood: -2852711\n",
      "INFO:lda:<330> log likelihood: -2851144\n",
      "INFO:lda:<340> log likelihood: -2851872\n",
      "INFO:lda:<350> log likelihood: -2852238\n",
      "INFO:lda:<360> log likelihood: -2851314\n",
      "INFO:lda:<370> log likelihood: -2850368\n",
      "INFO:lda:<380> log likelihood: -2850099\n",
      "INFO:lda:<390> log likelihood: -2848957\n",
      "INFO:lda:<400> log likelihood: -2849928\n",
      "INFO:lda:<410> log likelihood: -2850307\n",
      "INFO:lda:<420> log likelihood: -2849157\n",
      "INFO:lda:<430> log likelihood: -2849847\n",
      "INFO:lda:<440> log likelihood: -2850170\n",
      "INFO:lda:<450> log likelihood: -2848778\n",
      "INFO:lda:<460> log likelihood: -2848707\n",
      "INFO:lda:<470> log likelihood: -2848321\n",
      "INFO:lda:<480> log likelihood: -2849113\n",
      "INFO:lda:<490> log likelihood: -2848617\n",
      "INFO:lda:<499> log likelihood: -2847932\n",
      "WARNING:lda:all zero row in document-term matrix found\n",
      "WARNING:lda:all zero column in document-term matrix found\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.849635829253\n"
     ]
    }
   ],
   "source": [
    "# LDA + LinearSVC\n",
    "ldaClassifier(trainData,testData,trainLabel,testLabel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of fea_train:(40000, 10000)\n",
      "Size of fea_train:(10000, 10000)\n",
      "278363\n",
      "69546\n",
      "0.928409779329\n"
     ]
    }
   ],
   "source": [
    "# HashingVectorizer + (TfidfTransformer)+ rf\n",
    "rfClassifier(trainData,testData,trainLabel,testLabel)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
